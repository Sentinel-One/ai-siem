{
    "pipeline": {
        "id": "0",
        "siteId": "16",
        "name": "Pipeline Template_Cisco_Duo_Logs",
        "description": "This is the default Template to get data into SentinelOne AI-SIEM",
        "status": "DEFAULT",
        "createdAt": "2025-11-19T22:17:26.068060Z",
        "updatedAt": "2025-11-19T22:17:30.900628Z",
        "deletedAt": null,
        "createdBy": "",
        "updatedBy": "",
        "deployedGraphVersion": 0,
        "pendingGraphVersion": 0,
        "latestGraphVersion": 0,
        "sourceId": "0",
        "pipelineType": "PIPELINE_TYPE_USER",
        "pendingAction": "NOP",
        "analytics": []
    },
    "pipelineGraph": {
        "version": 1,
        "pipelineId": "0",
        "edges": {
            "100000000000000025": {
                "nodeIds": [
                    "300000000000000227"
                ]
            },
            "300000000000000227": {
                "nodeIds": [
                    "200000000000000044"
                ]
            }
        },
        "created": "2025-11-19T22:17:30.900628Z",
        "createdBy": "",
        "metaInfo": {
            "omissions": [
                {
                    "omitted": {
                        "300000000000000227": {
                            "nodeIds": [
                                "300000000000000229"
                            ]
                        },
                        "300000000000000229": {
                            "nodeIds": [
                                "200000000000000044"
                            ]
                        }
                    },
                    "patch": {
                        "300000000000000227": {
                            "nodeIds": [
                                "200000000000000044"
                            ]
                        }
                    }
                },
                {
                    "omitted": {
                        "100000000000000025": {
                            "nodeIds": [
                                "300000000000000228"
                            ]
                        },
                        "300000000000000228": {
                            "nodeIds": [
                                "300000000000000227"
                            ]
                        }
                    },
                    "patch": {
                        "100000000000000025": {
                            "nodeIds": [
                                "300000000000000227"
                            ]
                        }
                    }
                }
            ]
        }
    },
    "source": {
        "id": "100000000000000025",
        "siteId": "16",
        "templateId": "6",
        "templateVersion": "1",
        "templateName": "Cisco Duo Logs Collector",
        "name": "Source Template_Cisco_Duo_Logs",
        "description": "This is the Default approach to Send data into your SentinelOne Console",
        "config": {
            "config": {
                "DUO_API_HOST": "<your_host>.duosecurity.com",
                "DUO_INTEGRATION_KEY": "*****",
                "DUO_SECRET_KEY": "*****",
                "MAX_PAGE_CALLS": "10"
            },
            "retry.backoff_scaling_factor": 2,
            "retry.initial_backoff_secs": 1,
            "retry.max_backoff_secs": 5,
            "retry.max_retries": 4,
            "scale.completion_queue": 10,
            "scale.event_batch_queue": 10,
            "scale.fetch_req_queue": 1000,
            "scale.fetch_res_queue": 10,
            "scale.fetchers": 8,
            "scale.runtimes": 2,
            "script": "local json = require('json')\nlocal hmac = require('hmac')\nlocal codec = require('codec')\nlocal log = require('log')\n\nfunction no_nulls(d, rn)\n  if type(d) == \"table\" then\n      for k, v in pairs(d) do\n          if type(v) == \"userdata\" then\n              local ok, s = pcall(tostring, v)\n              if not ok then\n                  d[k] = rn\n              end\n              if s == \"userdata: (nil)\" then\n                  d[k] = rn\n              end\n              if s == \"userdata: 0x0\" then\n                  d[k] = rn\n              end\n          elseif type(v) == \"table\" then\n              no_nulls(v, rn)\n          end\n      end\n  end\nend\n\nfunction start(config)\n -- Convert MAX_PAGE_CALLS to number with a default fallback\n local max_page_calls = tonumber(config[\"MAX_PAGE_CALLS\"]) or 10\n \n -- Get checkpoints for each log type, or use defaults if none exist\n local auth_since_time = get_chkpt(\"AUTH_SINCE_TIME\")\n local admin_since_time = get_chkpt(\"ADMIN_SINCE_TIME\")\n local telephony_since_time = get_chkpt(\"TELEPHONY_SINCE_TIME\")\n\n -- Trigger independent fetch calls for each data type\n fetch_admin_logs(config, admin_since_time, nil, max_page_calls)\n\n -- Uncomment if you want to collect Duo Authentication logs\n fetch_auth_logs(config, auth_since_time, nil, max_page_calls)\n\n -- Uncomment if you want to collect Duo Telephony logs\n fetch_telephony_logs(config, telephony_since_time, nil, max_page_calls)\nend\n\n-- URL encoding function (replaces url library)\nfunction url_encode(str)\n if str then\n     str = string.gsub(str, \"\\n\", \"\\r\\n\")\n     str = string.gsub(str, \"([^%w _~%.%-])\", function(c)\n         return string.format(\"%%%02X\", string.byte(c))\n     end)\n     str = string.gsub(str, \" \", \"+\")\n end\n return str\nend\n\n-- Duo-specific authentication function\nfunction generate_duo_auth(method, host, path, params, ikey, skey)\n    local date = os.date(\"!%a, %d %b %Y %H:%M:%S +0000\")\n\n    -- Build canonical string\n    local canon = {}\n    table.insert(canon, date)\n    table.insert(canon, string.upper(method))\n    table.insert(canon, string.lower(host))\n    table.insert(canon, path)\n\n    -- Sort and encode parameters\n    local args = {}\n    local sorted_keys = {}\n    for key, _ in pairs(params or {}) do\n        table.insert(sorted_keys, key)\n    end\n    table.sort(sorted_keys)\n\n    for _, key in ipairs(sorted_keys) do\n        local encoded_key = url_encode(key)\n        local encoded_val = url_encode(tostring(params[key]))\n        table.insert(args, encoded_key .. \"=\" .. encoded_val)\n    end\n    table.insert(canon, table.concat(args, \"&\"))\n\n    local canonical_string = table.concat(canon, \"\\n\")\n\n -- Generate HMAC-SHA1 signature\n local signature = hmac.sha1(skey, canonical_string)\n local hex_signature = codec.hex_lower_encode(signature)\n\n    -- Create Basic Auth header\n    local auth_string = ikey .. \":\" .. hex_signature\n    local encoded_auth = codec.base64_encode(auth_string)\n\n    return {\n        [\"Date\"] = date,\n        [\"Authorization\"] = \"Basic \" .. encoded_auth,\n        [\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n    }\nend\n\nfunction build_auth_logs_query(since_time, next_offset)\n local params = {\n     limit = \"1000\"  -- Maximum allowed by Duo\n }\n\n -- Add maxtime (current time in milliseconds)\n params.maxtime = tostring(os.time() * 1000)\n\n if since_time and since_time ~= \"\" and since_time ~= \"0\" then\n     params.mintime = since_time\n else\n     -- Default to 30 days ago in milliseconds\n     params.mintime = tostring((os.time() - 30 * 24 * 60 * 60) * 1000)\n end\n\n if next_offset and next_offset ~= \"\" then\n     params.next_offset = next_offset\n end\n\n return params\nend\n\nfunction build_admin_logs_query(since_time, next_offset)\n    local params = {\n        limit = \"1000\"  -- Maximum allowed by Duo\n    }\n\n    -- Use only mintime parameter (like duo_test.py)\n    if since_time and since_time ~= \"\" and since_time ~= \"0\" then\n        params.mintime = since_time\n    else\n        -- Default to 30 days ago in milliseconds\n        params.mintime = tostring((os.time() - 30 * 24 * 60 * 60))\n    end\n\n    if next_offset and next_offset ~= \"\" then\n        params.next_offset = next_offset\n    end\n\n    return params\nend\n\nfunction build_telephony_logs_query(since_time, next_offset)\n    local params = {\n        limit = \"1000\"  -- Maximum allowed by Duo\n    }\n\n    -- Add maxtime (current time in milliseconds)\n    params.maxtime = tostring(os.time() * 1000)\n\n    if since_time and since_time ~= \"\" and since_time ~= \"0\" then\n        params.mintime = since_time\n    else\n        -- Default to 30 days ago in milliseconds\n        params.mintime = tostring((os.time() - 30 * 24 * 60 * 60) * 1000)\n    end\n\n    if next_offset and next_offset ~= \"\" then\n        params.next_offset = next_offset\n    end\n\n    return params\nend\n\nfunction fetch_auth_logs(config, auth_since_time, next_offset, page_calls_left)\n    if page_calls_left <= 0 then\n        log.info(\"Reached maximum page call limit for authentication logs\")\n        return\n    end\n    \n    local host = config[\"DUO_API_HOST\"]\n    local path = \"/admin/v2/logs/authentication\"\n    local method = \"GET\"\n    local params = build_auth_logs_query(auth_since_time, next_offset)\n\n    -- Generate authentication headers\n    local headers = generate_duo_auth(method, host, path, params,\n                                    config[\"DUO_INTEGRATION_KEY\"],\n                                    config[\"DUO_SECRET_KEY\"])\n\n    -- Build query string\n    local query_string = \"\"\n    local query_params = {}\n    for key, value in pairs(params) do\n        table.insert(query_params, key .. \"=\" .. url_encode(tostring(value)))\n    end\n    if #query_params > 0 then\n        query_string = \"?\" .. table.concat(query_params, \"&\")\n    end\n\n    fetch {\n        params = {\n            url = \"https://\" .. host .. path .. query_string,\n            method = method,\n            headers = headers\n        },\n        fn = \"process_auth_logs\",\n        retry = true,\n        context = {\n            request_time = os.time(),\n            auth_since_time_used = auth_since_time,\n            page_calls_left = page_calls_left\n        }\n    }\nend\n\nfunction process_auth_logs(config, response, context)\n    -- Decrement page calls left counter\n    local page_calls_left = context.page_calls_left - 1\n    \n    if response.status == 200 then\n        local data = json.decode(response.body)\n\n        if data and data.stat == \"OK\" and data.response then\n            local auth_logs = data.response\n            local latest_timestamp = context.auth_since_time_used\n\n            -- Emit each authentication log as a separate log\n            for _, log_entry in ipairs(auth_logs) do\n                -- Clean the log entry to remove unsupported data types\n                no_nulls(log_entry, \"-\")\n                log_entry.host = config[\"DUO_API_HOST\"]\n                log_entry._duo_event_type = \"authentication\"\n                log_entry._duo_query_time = os.date('%Y-%m-%dT%H:%M:%SZ', context.request_time)\n                emit{log = log_entry}\n\n                -- Track the latest timestamp for checkpointing\n                if log_entry.timestamp and tonumber(log_entry.timestamp) then\n                    local entry_time = tonumber(log_entry.timestamp)\n                    if not latest_timestamp or entry_time > tonumber(latest_timestamp or 0) then\n                        latest_timestamp = tostring(entry_time + 1)\n                    end\n                end\n            end\n\n            -- Update checkpoint with the latest timestamp\n            if latest_timestamp and #auth_logs > 0 then\n                set_chkpt(\"AUTH_SINCE_TIME\", latest_timestamp)\n            end\n\n            -- Check if there are more pages AND we have page calls left\n            if data.metadata and data.metadata.next_offset and page_calls_left > 0 then\n                fetch_auth_logs(config, context.auth_since_time_used, data.metadata.next_offset, page_calls_left)\n            elseif data.metadata and data.metadata.next_offset and page_calls_left <= 0 then\n                log.info(\"Reached maximum page call limit for authentication logs - will continue in next run\")\n            end\n        else\n            emit{log = {\n                message = \"No authentication log data found in response\",\n                response_body = response.body,\n                timestamp = context.request_time,\n                _duo_event_type = \"error\"\n            }}\n        end\n\n    elseif response.status == 401 then\n        emit{log = {\n            message = \"Authentication failed for Duo logs - check integration/secret keys\",\n            status = response.status,\n            timestamp = context.request_time,\n            _duo_event_type = \"error\"\n        }}\n    elseif response.status == 429 then\n        emit{log = {\n            message = \"Rate limit exceeded for Duo logs - will retry\",\n            status = response.status,\n            timestamp = context.request_time,\n            _duo_event_type = \"error\"\n        }}\n    elseif response.status == 400 then\n        emit{log = {\n            message = \"Bad request for Duo logs - check API parameters\",\n            status = response.status,\n            body = response.body,\n            timestamp = context.request_time,\n            _duo_event_type = \"error\"\n        }}\n    elseif response.status == 403 then\n        emit{log = {\n            message = \"Access forbidden - check API permissions (Grant read log required)\",\n            status = response.status,\n            body = response.body,\n            timestamp = context.request_time,\n            _duo_event_type = \"error\"\n        }}\n    else\n        emit{log = {\n            message = \"Failed to fetch Duo authentication logs\",\n            status = response.status,\n            body = response.body,\n            timestamp = context.request_time,\n            _duo_event_type = \"error\"\n        }}\n    end\nend\n\nfunction fetch_admin_logs(config, admin_since_time, next_offset, page_calls_left)\n    if page_calls_left <= 0 then\n        log.info(\"Reached maximum page call limit for administrator logs\")\n        return\n    end\n    \n    local host = config[\"DUO_API_HOST\"]\n    local path = \"/admin/v1/logs/administrator\"\n    local method = \"GET\"\n    local params = build_admin_logs_query(admin_since_time, next_offset)\n\n    -- Generate authentication headers\n    local headers = generate_duo_auth(method, host, path, params,\n                                    config[\"DUO_INTEGRATION_KEY\"],\n                                    config[\"DUO_SECRET_KEY\"])\n\n    -- Build query string\n    local query_string = \"\"\n    local query_params = {}\n    for key, value in pairs(params) do\n        table.insert(query_params, key .. \"=\" .. url_encode(tostring(value)))\n    end\n    if #query_params > 0 then\n        query_string = \"?\" .. table.concat(query_params, \"&\")\n    end\n\n    fetch {\n        params = {\n            url = \"https://\" .. host .. path .. query_string,\n            method = method,\n            headers = headers\n        },\n        fn = \"process_admin_logs\",\n        retry = true,\n        context = {\n            request_time = os.time(),\n            admin_since_time_used = admin_since_time,\n            page_calls_left = page_calls_left\n        }\n    }\nend\n\nfunction process_admin_logs(config, response, context)\n    -- Decrement page calls left counter\n    local page_calls_left = context.page_calls_left - 1\n    \n    if response.status == 200 then\n        local data = json.decode(response.body)\n\n        if data and data.stat == \"OK\" and data.response then\n            local admin_logs = data.response\n            local latest_timestamp = context.admin_since_time_used\n            -- Emit each administrator log as a separate log\n            for _, log_entry in ipairs(admin_logs) do\n                -- Clean the log entry to remove unsupported data types\n                no_nulls(log_entry, \"-\")\n                log_entry.host = config[\"DUO_API_HOST\"]\n                log_entry._duo_event_type = \"administrator\"\n                log_entry._duo_query_time = os.date('%Y-%m-%dT%H:%M:%SZ', context.request_time)\n                emit{log = log_entry}\n\n                -- Track the latest timestamp for checkpointing\n                if log_entry.timestamp and tonumber(log_entry.timestamp) then\n                    local entry_time = tonumber(log_entry.timestamp)\n                    if not latest_timestamp or entry_time > tonumber(latest_timestamp or 0) then\n                        latest_timestamp = tostring(entry_time+1)\n                    end\n                end\n            end\n\n            -- Update checkpoint with the latest timestamp\n            if latest_timestamp and #admin_logs > 0 then\n                set_chkpt(\"ADMIN_SINCE_TIME\", latest_timestamp)\n            end\n\n            -- Check if there are more pages AND we have page calls left\n            if data.metadata and data.metadata.next_offset and page_calls_left > 0 then\n                fetch_admin_logs(config, context.admin_since_time_used, data.metadata.next_offset, page_calls_left)\n            elseif data.metadata and data.metadata.next_offset and page_calls_left <= 0 then\n                log.info(\"Reached maximum page call limit for administrator logs - will continue in next run\")\n            end\n        else\n            emit{log = {\n                message = \"No administrator log data found in response\",\n                response_body = response.body,\n                timestamp = context.request_time,\n                _duo_event_type = \"error\"\n            }}\n        end\n\n    elseif response.status == 401 then\n        emit{log = {\n            message = \"Authentication failed for Duo admin logs - check integration/secret keys\",\n            status = response.status,\n            timestamp = context.request_time,\n            _duo_event_type = \"error\"\n        }}\n    elseif response.status == 429 then\n        emit{log = {\n            message = \"Rate limit exceeded for Duo admin logs - will retry\",\n            status = response.status,\n            timestamp = context.request_time,\n            _duo_event_type = \"error\"\n        }}\n    else\n        emit{log = {\n            message = \"Failed to fetch Duo administrator logs\",\n            status = response.status,\n            body = response.body,\n            timestamp = context.request_time,\n            _duo_event_type = \"error\"\n        }}\n    end\nend\n\nfunction fetch_telephony_logs(config, telephony_since_time, next_offset, page_calls_left)\n    if page_calls_left <= 0 then\n        log.info(\"Reached maximum page call limit for telephony logs\")\n        return\n    end\n    \n    local host = config[\"DUO_API_HOST\"]\n    local path = \"/admin/v2/logs/telephony\"\n    local method = \"GET\"\n    local params = build_telephony_logs_query(telephony_since_time, next_offset)\n\n    -- Generate authentication headers\n    local headers = generate_duo_auth(method, host, path, params,\n                                    config[\"DUO_INTEGRATION_KEY\"],\n                                    config[\"DUO_SECRET_KEY\"])\n\n    -- Build query string\n    local query_string = \"\"\n    local query_params = {}\n    for key, value in pairs(params) do\n        table.insert(query_params, key .. \"=\" .. url_encode(tostring(value)))\n    end\n    if #query_params > 0 then\n        query_string = \"?\" .. table.concat(query_params, \"&\")\n    end\n\n    fetch {\n        params = {\n            url = \"https://\" .. host .. path .. query_string,\n            method = method,\n            headers = headers\n        },\n        fn = \"process_telephony_logs\",\n        retry = true,\n        context = {\n            request_time = os.time(),\n            telephony_since_time_used = telephony_since_time,\n            page_calls_left = page_calls_left\n        }\n    }\nend\n\nfunction process_telephony_logs(config, response, context)\n    -- Decrement page calls left counter\n    local page_calls_left = context.page_calls_left - 1\n    \n    if response.status == 200 then\n        local data = json.decode(response.body)\n\n        if data and data.stat == \"OK\" and data.response then\n            local telephony_logs = data.response\n            local latest_timestamp = context.telephony_since_time_used\n\n            -- Emit each telephony log as a separate log\n            for _, log_entry in ipairs(telephony_logs) do\n                -- Clean the log entry to remove unsupported data types\n                no_nulls(log_entry, \"-\")\n                log_entry.host = config[\"DUO_API_HOST\"]\n                log_entry._duo_event_type = \"telephony\"\n                log_entry._duo_query_time = os.date('%Y-%m-%dT%H:%M:%SZ', context.request_time)\n                emit{log = log_entry}\n\n                -- Track the latest timestamp for checkpointing\n                if log_entry.timestamp and tonumber(log_entry.timestamp) then\n                    local entry_time = tonumber(log_entry.timestamp)\n                    if not latest_timestamp or entry_time > tonumber(latest_timestamp or 0) then\n                        latest_timestamp = tostring(entry_time+1)\n                    end\n                end\n            end\n\n            -- Update checkpoint with the latest timestamp\n            if latest_timestamp and #telephony_logs > 0 then\n                set_chkpt(\"TELEPHONY_SINCE_TIME\", latest_timestamp)\n            end\n\n            -- Check if there are more pages AND we have page calls left\n            if data.metadata and data.metadata.next_offset and page_calls_left > 0 then\n                fetch_telephony_logs(config, context.telephony_since_time_used, data.metadata.next_offset, page_calls_left)\n            elseif data.metadata and data.metadata.next_offset and page_calls_left <= 0 then\n                log.info(\"Reached maximum page call limit for telephony logs - will continue in next run\")\n            end\n        else\n            emit{log = {\n                message = \"No telephony log data found in response\",\n                response_body = response.body,\n                timestamp = context.request_time,\n                _duo_event_type = \"error\"\n            }}\n        end\n\n    elseif response.status == 401 then\n        emit{log = {\n            message = \"Authentication failed for Duo telephony logs - check integration/secret keys\",\n            status = response.status,\n            timestamp = context.request_time,\n            _duo_event_type = \"error\"\n        }}\n    elseif response.status == 429 then\n        emit{log = {\n            message = \"Rate limit exceeded for Duo telephony logs - will retry\",\n            status = response.status,\n            timestamp = context.request_time,\n            _duo_event_type = \"error\"\n        }}\n    else\n        emit{log = {\n            message = \"Failed to fetch Duo telephony logs\",\n            status = response.status,\n            body = response.body,\n            timestamp = context.request_time,\n            _duo_event_type = \"error\"\n        }}\n    end\nend\n",
            "seed_checkpoints": {
                "ADMIN_SINCE_TIME": "1661022959",
                "AUTH_SINCE_TIME": "1661022959934",
                "TELEPHONY_SINCE_TIME": "1661022959934"
            },
            "start_routine": "start",
            "trigger.interval_secs": 300
        },
        "status": "NS_ACTIVE",
        "created": "2025-11-19T22:15:50.654183Z",
        "updated": "2025-11-19T22:15:50.654183Z",
        "createdBy": "",
        "updatedBy": "",
        "type": "SCOL",
        "origin": "NODE_ORIGIN_USER",
        "archivalInfo": null,
        "logFormat": "LOG_FORMAT_UNSPECIFIED",
        "preprocessorConfig": null,
        "port": 0,
        "pushBased": false,
        "pushSourceAddress": "",
        "k8sInternalSvcUrl": "",
        "siteFilenames": [],
        "sourceConfigs": [
            {
                "id": "0",
                "sourceId": "0",
                "templateId": "30",
                "templateName": "JSON",
                "category": "PARSER",
                "config": {
                    "config_groups": [
                        {
                            "_name": "General Configuration",
                            "bypassed": false,
                            "filterEnabled": false
                        },
                        {
                            "_name": "jsonParser",
                            "enabled": true,
                            "jsons": [
                                {
                                    "explode_array_events": true,
                                    "merge_with_exploded": true,
                                    "old_field": "message"
                                }
                            ]
                        }
                    ]
                },
                "position": 0,
                "templateVersion": "1"
            },
            {
                "id": "0",
                "sourceId": "0",
                "templateId": "65",
                "templateName": "PatternExtractorPostProcessor",
                "category": "PATTERN_EXTRACTOR",
                "config": {
                    "config_groups": [
                        {
                            "_name": "Pattern Extractor Configs",
                            "clusterTagNames": [],
                            "truncate": false
                        }
                    ]
                },
                "position": 1,
                "templateVersion": "1"
            },
            {
                "id": "0",
                "sourceId": "0",
                "templateId": "46",
                "templateName": "SentimentAnalyzer",
                "category": "PATTERN_EXTRACTOR",
                "config": {
                    "config_groups": [
                        {
                            "_name": "Config",
                            "enabled": false,
                            "keyNameForExtractedSentiment": "sentiment",
                            "logLocations": [],
                            "negativeSentimentRegexes": [
                                "time[\\s_-]*out",
                                "timed[\\s_-]*out",
                                "(?i)alert ([=\\s\\*]+|$)",
                                "(?i)bad[\\s_-]*gateway",
                                "(?i)bad[\\s_-]*request",
                                "(?i)(^| [=\\s\\*]+)bad([=\\s\\*]+|$)",
                                "(?i)does[\\s_-]*not[\\s_-]*exist",
                                "(?i)[=\\s\\*]+eof([=\\s\\*]+|$)",
                                "(?i)exception([=\\s\\*]+|$)",
                                "(?i)fail([=\\s\\*]+|$)",
                                "(?i)failed([=\\s\\*]+|$)",
                                "(?i)failure([=\\s\\*]+|$)",
                                "(?i)(^|[=\\s\\*]+)fault([=\\s\\*]+|$)",
                                "(?i)(^| [=\\s\\*]+)feof([=\\s\\*]+|$)",
                                "(?i)not[\\s_-]*acceptable",
                                "(?i)not[\\s_-]*allowed",
                                "(?i)not[\\s_-]*found",
                                "(?i)not[\\s_-]*ok",
                                "(?i)(^| [=\\s\\*]+)oom([=\\s\\*]+|$)",
                                "(?i)too[\\s_-]*many"
                            ],
                            "negativeSentimentWords": [
                                "abnormal",
                                "abort",
                                "broken",
                                "canceled",
                                "caught",
                                "critical",
                                "denied",
                                "emergency",
                                "error",
                                "exception",
                                "fatal",
                                "incomplete",
                                "insufficient",
                                "interrupt",
                                "killed",
                                "killing",
                                "malformed",
                                "mismatch",
                                "outofmemory",
                                "panic",
                                "segfault",
                                "terminate",
                                "timeout",
                                "unable",
                                "unauthorized",
                                "undefined",
                                "unexpected",
                                "unprocessable",
                                "unstable",
                                "unhandled",
                                "unsuccessful",
                                "unusable",
                                "violation",
                                "rejection",
                                "rejected"
                            ],
                            "useLogPath": true
                        }
                    ]
                },
                "position": 2,
                "templateVersion": "1"
            },
            {
                "id": "0",
                "sourceId": "0",
                "templateId": "71",
                "templateName": "GeneratorVersion",
                "category": "INTERNAL",
                "config": {
                    "generator_version": "v2"
                },
                "position": 0,
                "templateVersion": "0"
            }
        ],
        "userVisible": true,
        "usageType": "USER"
    },
    "destinations": [
        {
            "id": "200000000000000044",
            "siteId": "16",
            "templateId": "25",
            "templateVersion": "0",
            "templateName": "SentinelOne AI SIEM",
            "name": "Sink Template_SentinelOne AI SIEM",
            "description": "This is the Default approach to Send data into your SentinelOne Console",
            "config": {
                "acknowledgements.enabled": false,
                "acknowledgements.indexer_acknowledgements_enabled": true,
                "acknowledgements.query_interval": 10,
                "acknowledgements.retry_limit": 30,
                "batch.timeout_secs": 1,
                "compression": "none",
                "default_token": "********",
                "encoding.codec": "json",
                "encoding.json.pretty": false,
                "encoding.metric_tag_values": "single",
                "endpoint": "https://ingest.us1.sentinelone.net",
                "endpoint_target": "event",
                "host_key": "host",
                "path": "/services/collector/event?isParsed=true",
                "request.concurrency": "adaptive",
                "request.headers": {},
                "request.rate_limit_duration_secs": 1,
                "request.retry_initial_backoff_secs": 1,
                "request.retry_max_duration_secs": 3600,
                "request.timeout_secs": 60,
                "timestamp_key": "timestamp",
                "tls.verify_certificate": false,
                "tls.verify_hostname": false
            },
            "status": "NS_ACTIVE",
            "sourceId": "0",
            "created": "2025-11-16T22:17:36.683043Z",
            "updated": "2025-11-20T17:19:18.696952Z",
            "createdBy": "",
            "updatedBy": "",
            "type": "SPLUNK_HEC_LOGS",
            "origin": "NODE_ORIGIN_USER",
            "usageType": "USER",
            "siteFilenames": [],
            "userVisible": true
        }
    ],
    "transforms": [
        {
            "id": "300000000000000227",
            "siteId": "16",
            "templateId": "60",
            "templateVersion": "2",
            "name": "Transform Template_Cisco_Duo_Logs",
            "description": "",
            "pipelineId": "0",
            "config": {
                "config_groups": [
                    {
                        "_name": "General Configuration",
                        "bypassed": false,
                        "filterEnabled": false
                    },
                    {
                        "_name": "ocsf",
                        "enabled": true,
                        "parallelism": 1,
                        "script": "local FEATURES = {\n    FLATTEN_EVENT_TYPE = true,\n}\n\n-- Cisco Duo to OCSF Mapping Script\nlocal OCSF_VERSION = \"1.0.0\"\nlocal VENDOR = \"Cisco\"\nlocal PRODUCT = \"Cisco Duo\"\nlocal CATEGORY_SECURITY = \"security\"\nlocal CATEGORY_IAM = \"Identity & Access Management\"\nlocal CATEGORY_APP = \"Application Activity\"\n\n-- Authentication Event Mappings\nlocal authenticationMappings = {\n    -- OCSF structure fields (first)\n    {type=\"computed\", value=1, target=\"activity_id\"},\n    {type=\"computed\", value=\"Logon\", target=\"activity_name\"},\n    {type=\"computed\", value=3, target=\"category_uid\"},\n    {type=\"computed\", value=CATEGORY_IAM, target=\"category_name\"},\n    {type=\"computed\", value=3002, target=\"class_uid\"},\n    {type=\"computed\", value=\"Authentication\", target=\"class_name\"},\n    {type=\"computed\", value=300201, target=\"type_uid\"},\n    {type=\"computed\", value=\"Authentication: Logon\", target=\"type_name\"},\n    {type=\"computed\", value=\"Logon\", target=\"event.type\"},\n    {type=\"computed\", value=\"True\", target=\"is_mfa\"},\n    {type=\"computed\", value=VENDOR, target=\"metadata.product.vendor_name\"},\n    {type=\"computed\", value=VENDOR, target=\"metadata.product.name\"},\n    {type=\"computed\", value=OCSF_VERSION, target=\"metadata.version\"},\n    {type=\"computed\", value=CATEGORY_SECURITY, target=\"dataSource.category\"},\n    {type=\"computed\", value=PRODUCT, target=\"dataSource.name\"},\n    {type=\"computed\", value=VENDOR, target=\"dataSource.vendor\"},\n    {type=\"computed\", value=OCSF_VERSION, target=\"OCSF_version\"},\n    \n    -- Direct field mappings (ordered to match expected output)\n    {type=\"direct\", source=\"isotimestamp\", target=\"time\"},\n    {type=\"direct\", source=\"timestamp\", target=\"metadata.original_time\"},\n    {type=\"direct\", source=\"access_device.hostname\", target=\"dst_endpoint.hostname\"},\n    {type=\"direct\", source=\"access_device.ip\", target=\"dst_endpoint.ip\"},\n    {type=\"direct\", source=\"access_device.location.city\", target=\"dst_endpoint.location.city\"},\n    {type=\"direct\", source=\"access_device.location.country\", target=\"dst_endpoint.location.country\"},\n    {type=\"direct\", source=\"application.key\", target=\"service.uid\"},\n    {type=\"direct\", source=\"application.name\", target=\"service.name\"},\n    {type=\"direct\", source=\"txid\", target=\"session.uid\"},\n    {type=\"direct\", source=\"auth_device.ip\", target=\"src_endpoint.ip\"},\n    {type=\"direct\", source=\"auth_device.key\", target=\"src_endpoint.uid\"},\n    {type=\"direct\", source=\"auth_device.location.city\", target=\"src_endpoint.location.city\"},\n    {type=\"direct\", source=\"auth_device.location.country\", target=\"src_endpoint.location.country\"},\n    {type=\"direct\", source=\"auth_device.name\", target=\"src_endpoint.name\"},\n    {type=\"direct\", source=\"result\", target=\"status\"},\n    {type=\"direct\", source=\"reason\", target=\"status_detail\"},\n    {type=\"direct\", source=\"user.key\", target=\"user.uid\"},\n    {type=\"direct\", source=\"user.name\", target=\"user.name\"},\n    {type=\"direct\", source=\"user.groups\", target=\"user.groups.name\"},\n    {type=\"direct\", source=\"email\", target=\"user.email_addr\"},\n    \n    -- Observables\n    {type=\"observable\", source=\"access_device.hostname\", type_id=1, observable_type=\"Hostname\", name=\"dst_endpoint.hostname\"},\n    {type=\"observable\", source=\"access_device.ip\", type_id=2, observable_type=\"IP Address\", name=\"src_endpoint.ip\"},\n    {type=\"observable\", source=\"user.name\", type_id=4, observable_type=\"User Name\", name=\"user.name\"},\n    {type=\"observable\", source=\"email\", type_id=5, observable_type=\"Email Address\", name=\"user.email_addr\"},\n    {type=\"observable\", source=\"application.name\", type_id=9, observable_type=\"Process Name\", name=\"service.name\"},\n    \n}\n\n-- Administrator Event Mappings\nlocal administratorMappings = {\n    -- OCSF structure fields (first)\n    {type=\"computed\", value=VENDOR, target=\"metadata.product.vendor_name\"},\n    {type=\"computed\", value=VENDOR, target=\"metadata.product.name\"},\n    {type=\"computed\", value=OCSF_VERSION, target=\"metadata.version\"},\n    {type=\"computed\", value=CATEGORY_SECURITY, target=\"dataSource.category\"},\n    {type=\"computed\", value=PRODUCT, target=\"dataSource.name\"},\n    {type=\"computed\", value=VENDOR, target=\"dataSource.vendor\"},\n    {type=\"computed\", value=OCSF_VERSION, target=\"OCSF_version\"},\n    \n    -- Direct field mappings (ordered to match expected output)\n    {type=\"direct\", source=\"username\", target=\"actor.user.name\"},\n    {type=\"direct\", source=\"host\", target=\"device.hostname\"},\n    {type=\"direct\", source=\"isotimestamp\", target=\"time\"},\n    {type=\"direct\", source=\"timestamp\", target=\"metadata.original_time\"},\n    {type=\"direct\", source=\"object\", target=\"user.name\"},\n    \n    -- Observables\n    {type=\"observable\", source=\"host\", type_id=1, observable_type=\"Hostname\", name=\"dst_endpoint.hostname\"},\n    {type=\"observable\", source=\"username\", type_id=4, observable_type=\"User Name\", name=\"actor.user.name\"},\n    \n}\n\n-- Telephony Event Mappings\nlocal telephonyMappings = {\n    -- OCSF structure fields (first)\n    {type=\"computed\", value=VENDOR, target=\"metadata.product.vendor_name\"},\n    {type=\"computed\", value=VENDOR, target=\"metadata.product.name\"},\n    {type=\"computed\", value=OCSF_VERSION, target=\"metadata.version\"},\n    {type=\"computed\", value=CATEGORY_SECURITY, target=\"dataSource.category\"},\n    {type=\"computed\", value=PRODUCT, target=\"dataSource.name\"},\n    {type=\"computed\", value=VENDOR, target=\"dataSource.vendor\"},\n    {type=\"computed\", value=OCSF_VERSION, target=\"OCSF_version\"},\n    \n    -- Direct field mappings (ordered to match expected output)\n    {type=\"direct\", source=\"txid\", target=\"actor.session.uid\"},\n    \n}\n\n-- Common field mappings for all events (ordered to match expected output)\nlocal commonMappings = {\n    {type=\"direct\", source=\"event.type\", target=\"event.type\"},\n    {type=\"direct\", source=\"category_name\", target=\"category_name\"},\n    {type=\"direct\", source=\"category_uid\", target=\"category_uid\"},\n    {type=\"direct\", source=\"class_uid\", target=\"class_uid\"},\n    {type=\"direct\", source=\"activity_name\", target=\"activity_name\"},\n    {type=\"direct\", source=\"activity_id\", target=\"activity_id\"},\n    {type=\"direct\", source=\"type_uid\", target=\"type_uid\"},\n    {type=\"direct\", source=\"OCSF_version\", target=\"metadata.version\"},\n    {type=\"direct\", source=\"observables\", target=\"observables\"},\n    {type=\"direct\", source=\"dataSource.category\", target=\"dataSource.category\"},\n    {type=\"direct\", source=\"site.id\", target=\"site.id\"},\n    {type=\"direct\", source=\"dataSource.name\", target=\"dataSource.name\"},\n    {type=\"direct\", source=\"dataSource.vendor\", target=\"dataSource.vendor\"},\n    {type=\"direct\", source=\"message\", target=\"message\"},\n    {type=\"direct\", source=\"class_name\", target=\"class_name\"},\n    {type=\"direct\", source=\"type_name\", target=\"type_name\"},\n    {type=\"direct\", source=\"user.type_id\", target=\"user.type_id\"},\n    {type=\"direct\", source=\"isotimestamp\", target=\"time\"},\n    {type=\"direct\", source=\"timestamp\", target=\"metadata.original_time\"},\n    {type=\"direct\", source=\"object\", target=\"user.name\"},\n    {type=\"direct\", source=\"username\", target=\"actor.user.name\"}\n}\nlocal IGNORE_FIELDS = { _duo_event_type = true, _duo_query_time = true, _ts = true, _ob = true }\n\n-- Helper function to combine mappings\nlocal function combineMappings(common, specific)\n    local combined = {}\n    for _, mapping in ipairs(common) do\n        table.insert(combined, mapping)\n    end\n    for _, mapping in ipairs(specific) do\n        table.insert(combined, mapping)\n    end\n    return combined\nend\n\n-- Event type specific mappings\nlocal eventTypeMappings = {\n    [\"authentication.authentication\"] = {\n        mappings = combineMappings(commonMappings, authenticationMappings),\n        activity_id = 1, activity_name = \"Logon\", category_uid = 3, category_name = CATEGORY_IAM,\n        class_uid = 3002, class_name = \"Authentication\", type_uid = 300201, \n        type_name = \"Authentication: Logon\", event_type = \"Logon\", is_mfa = \"True\"\n    },\n    [\"administrator.admin_create\"] = {\n        mappings = combineMappings(commonMappings, administratorMappings),\n        activity_id = 1, activity_name = \"Create\", category_uid = 3, category_name = CATEGORY_IAM,\n        class_uid = 3001, class_name = \"Account Change\", type_uid = 300101,\n        type_name = \"Account Change: Create\", event_type = \"Create\", user_type_id = 2, status_id = 99\n    },\n    [\"administrator.admin_login\"] = {\n        mappings = combineMappings(commonMappings, administratorMappings),\n        activity_id = 1, activity_name = \"Logon\", category_uid = 3, category_name = CATEGORY_IAM,\n        class_uid = 3002, class_name = \"Authentication\", type_uid = 300202,\n        type_name = \"Authentication: Logon\", event_type = \"Logon\", user_type_id = 2\n    },\n    [\"administrator.admin_reset_password\"] = {\n        mappings = combineMappings(commonMappings, administratorMappings),\n        activity_id = 4, activity_name = \"Password Reset\", category_uid = 3, category_name = CATEGORY_IAM,\n        class_uid = 3001, class_name = \"Account Change\", type_uid = 300104,\n        type_name = \"Account Change: Password Reset\", event_type = \"Password Reset\", user_type_id = 2\n    },\n    [\"administrator.admin_update\"] = {\n        mappings = combineMappings(commonMappings, administratorMappings),\n        activity_id = 3, activity_name = \"Update\", category_uid = 3, category_name = CATEGORY_IAM,\n        class_uid = 3004, class_name = \"Entity Management\", type_uid = 300403,\n        type_name = \"Entity Management: Update\", event_type = \"Update\", cloud_provider = \"Cisco\"\n    },\n    [\"administrator.group_create\"] = {\n        mappings = combineMappings(commonMappings, administratorMappings),\n        activity_id = 1, activity_name = \"Create\", category_uid = 3, category_name = CATEGORY_IAM,\n        class_uid = 3004, class_name = \"Entity Management\", type_uid = 300401,\n        type_name = \"Entity Management: Create\", event_type = \"Create\", cloud_provider = \"Cisco\"\n    },\n    [\"administrator.group_delete\"] = {\n        mappings = combineMappings(commonMappings, administratorMappings),\n        activity_id = 4, activity_name = \"Delete\", category_uid = 3, category_name = CATEGORY_IAM,\n        class_uid = 3004, class_name = \"Entity Management\", type_uid = 300404,\n        type_name = \"Entity Management: Delete\", event_type = \"Delete\", cloud_provider = \"Cisco\"\n    },\n    [\"administrator.group_update\"] = {\n        mappings = combineMappings(commonMappings, administratorMappings),\n        activity_id = 3, activity_name = \"Update\", category_uid = 3, category_name = CATEGORY_IAM,\n        class_uid = 3004, class_name = \"Entity Management\", type_uid = 300403,\n        type_name = \"Entity Management: Update\", event_type = \"Update\", cloud_provider = \"Cisco\"\n    },\n    [\"administrator.user_create\"] = {\n        mappings = combineMappings(commonMappings, administratorMappings),\n        activity_id = 1, activity_name = \"Create\", category_uid = 3, category_name = CATEGORY_IAM,\n        class_uid = 3001, class_name = \"Account Change\", type_uid = 300101,\n        type_name = \"Account Change: Create\", event_type = \"Create\", user_type_id = 2\n    },\n    [\"administrator.user_delete\"] = {\n        mappings = combineMappings(commonMappings, administratorMappings),\n        activity_id = 6, activity_name = \"Delete\", category_uid = 3, category_name = CATEGORY_IAM,\n        class_uid = 3001, class_name = \"Account Change\", type_uid = 300106,\n        type_name = \"Account Change: Delete\", event_type = \"Delete\", user_type_id = 2\n    },\n    [\"administrator.user_update\"] = {\n        mappings = combineMappings(commonMappings, administratorMappings),\n        activity_id = 3, activity_name = \"Update\", category_uid = 3, category_name = CATEGORY_IAM,\n        class_uid = 3004, class_name = \"Entity Management\", type_uid = 300403,\n        type_name = \"Entity Management: Update\", event_type = \"Update\", cloud_provider = \"Cisco\"\n    },\n    [\"administrator.activation_set_password\"] = {\n        mappings = combineMappings(commonMappings, administratorMappings),\n        activity_id = 2, activity_name = \"Enable\", category_uid = 3, category_name = CATEGORY_IAM,\n        class_uid = 3001, class_name = \"Account Change\", type_uid = 300101,\n        type_name = \"Account Change: Enable\", event_type = \"Enable\", user_type_id = 2\n    },\n    [\"administrator.admin_login_error\"] = {\n        mappings = combineMappings(commonMappings, administratorMappings),\n        activity_id = 1, activity_name = \"Logon\", category_uid = 3, category_name = CATEGORY_IAM,\n        class_uid = 3002, class_name = \"Authentication\", type_uid = 300202,\n        type_name = \"Authentication: Logon\", event_type = \"Logon\", user_type_id = 2\n    },\n    [\"administrator.admin_lockout\"] = {\n        mappings = combineMappings(commonMappings, administratorMappings),\n        activity_id = 9, activity_name = \"Lock\", category_uid = 3, category_name = CATEGORY_IAM,\n        class_uid = 3001, class_name = \"Account Change\", type_uid = 300109,\n        type_name = \"Account Change: Lock\", event_type = \"Lock\", user_type_id = 2\n    },\n    [\"telephony.enrollment\"] = {\n        mappings = combineMappings(commonMappings, telephonyMappings),\n        activity_id = 1, activity_name = \"Create\", category_uid = 3, category_name = CATEGORY_IAM,\n        class_uid = 3001, class_name = \"Account Change\", type_uid = 300201,\n        type_name = \"Account Change: Create\", event_type = \"Create\"\n    },\n    [\"telephony.authentication\"] = {\n        mappings = combineMappings(commonMappings, telephonyMappings),\n        activity_id = 1, activity_name = \"Logon\", category_uid = 3, category_name = CATEGORY_IAM,\n        class_uid = 3002, class_name = \"Authentication\", type_uid = 300201,\n        type_name = \"Authentication: Logon\", event_type = \"Logon\"\n    },\n    [\"telephony.administrator login\"] = {\n        mappings = combineMappings(commonMappings, telephonyMappings),\n        activity_id = 1, activity_name = \"Logon\", category_uid = 3, category_name = CATEGORY_IAM,\n        class_uid = 3002, class_name = \"Authentication\", type_uid = 300201,\n        type_name = \"Authentication: Logon\", event_type = \"Logon\"\n    },\n    [\"unknown.unknown\"] = {\n        mappings = commonMappings,\n        activity_id = 99, activity_name = \"Other\", category_uid = 6, category_name = CATEGORY_APP,\n        class_uid = 6003, class_name = \"API Activity\", type_uid = 600399,\n        type_name = \"API Activity: Other\", event_type = \"Other\"\n    }\n}\n\nfunction getNestedField(obj, path)\n    if not obj or not path or path == '' then return nil end\n    local current = obj\n    for key in string.gmatch(path, '[^.]+') do\n        if not current or not key then return nil end\n        current = current[key]\n    end\n    return current\nend\n\nfunction setNestedField(obj, path, value)\n    if not value or not path or path == '' then return end\n    local keys = {}\n    for key in string.gmatch(path, '[^.]+') do\n        table.insert(keys, key)\n    end\n    local current = obj\n    for i = 1, #keys - 1 do\n        if not current[keys[i]] then current[keys[i]] = {} end\n        current = current[keys[i]]\n    end\n    current[keys[#keys]] = value\nend\n\nfunction json_encode(obj, key)\n    if obj == nil then return \"null\" end\n    if type(obj) == \"boolean\" or type(obj) == \"number\" then return tostring(obj) end\n    if type(obj) == \"string\" then return '\"' .. obj:gsub('\"', '\\\\\"') .. '\"' end\n    if type(obj) == \"table\" then\n        local isArray = true\n        local maxIndex = 0\n        for k, v in pairs(obj) do\n            if type(k) ~= \"number\" then isArray = false; break end\n            maxIndex = math.max(maxIndex, k)\n        end\n        \n        if isArray then\n            if maxIndex > 0 then\n            local items = {}\n            for i = 1, maxIndex do\n                    if obj[i] ~= nil then\n                        table.insert(items, json_encode(obj[i], key))\n                    else\n                        table.insert(items, \"null\")\n                    end\n                end\n                return \"[\" .. table.concat(items, \", \") .. \"]\"\n            else\n                return \"[]\"\n            end\n        else\n            local items = {}\n            for k, v in pairs(obj) do\n                    local keyStr = type(k) == \"string\" and k or tostring(k)\n                    table.insert(items, '\"' .. keyStr:gsub('\"', '\\\\\"') .. '\": ' .. json_encode(v, keyStr))\n            end\n            return \"{\" .. table.concat(items, \", \") .. \"}\"\n        end\n    end\n    return '\"' .. tostring(obj) .. '\"'\nend\n\n-- Field ordering maps for consistent JSON serialization (preorder traversal)\nlocal FIELD_ORDERS = {\n    access_device = {\n        \"hostname\", \"browser_version\", \"browser\", \"security_agents\", \"os_version\", \n        \"is_password_set\", \"java_version\", \"os\", \"location\", \"is_firewall_enabled\", \n        \"ip\", \"flash_version\", \"is_encryption_enabled\"\n    },\n    location = {\n        \"city\", \"state\", \"country\"\n    },\n    adaptive_trust_assessments = {\n        \"more_secure_auth\", \"remember_me\"\n    },\n    more_secure_auth = {\n        \"features_version\", \"model_version\", \"policy_enabled\", \"trust_level\", \"reason\"\n    },\n    remember_me = {\n        \"features_version\", \"model_version\", \"policy_enabled\", \"trust_level\", \"reason\"\n    },\n    application = {\n        \"name\", \"key\"\n    },\n    auth_device = {\n        \"name\", \"ip\", \"location\", \"key\"\n    },\n    user = {\n        \"key\", \"name\", \"groups\"\n    },\n    message = {\n        \"access_device\", \"adaptive_trust_assessments\", \"alias\", \"application\", \n        \"auth_device\", \"email\", \"event_type\", \"factor\", \"isotimestamp\", \n        \"ood_software\", \"reason\", \"result\", \"timestamp\", \"trusted_endpoint_status\", \n        \"txid\", \"user\", \"site\"\n    },\n    admin_message = {\n        \"action\", \"description\", \"isotimestamp\", \"object\", \"timestamp\", \n        \"username\", \"eventtype\", \"host\", \"site\"\n    },\n    -- Unified message field order for all event types (admin/auth/telephony)\n    message_all = {\n        -- Administrator-style fields first\n        \"action\", \"description\", \"isotimestamp\", \"object\", \"timestamp\",\n        \"username\", \"eventtype\", \"host\", \"site\",\n        -- Authentication/telephony-style fields afterwards\n        \"access_device\", \"adaptive_trust_assessments\", \"alias\", \"application\",\n        \"auth_device\", \"email\", \"event_type\", \"factor\",\n        \"ood_software\", \"reason\", \"result\", \"trusted_endpoint_status\",\n        -- Ensure deterministic ordering for common telephony fields\n        \"txid\", \"phone\", \"credits\", \"ts\", \"context\", \"telephony_id\", \"type\",\n        \"user\"\n    }\n}\n\n-- Helper function to encode objects with specific field order (preorder traversal)\nfunction encodeWithFieldOrder(obj, fieldOrder)\n    local items = {}\n    -- Phase 1: Process fields in predefined order\n    for _, fieldName in ipairs(fieldOrder) do\n        if obj[fieldName] ~= nil then\n            local valueStr = json_encode_ordered(obj[fieldName], fieldName)\n            table.insert(items, '\"' .. fieldName .. '\": ' .. valueStr)\n        end\n    end\n    -- Phase 2: Process remaining fields not in the order list\n    for k, v in pairs(obj) do\n        local found = false\n        for _, fieldName in ipairs(fieldOrder) do\n            if k == fieldName then found = true; break end\n        end\n        if not found then\n            local valueStr = json_encode_ordered(v, k)\n            table.insert(items, '\"' .. k .. '\": ' .. valueStr)\n        end\n    end\n    return \"{\" .. table.concat(items, \", \") .. \"}\"\nend\n\nfunction json_encode_ordered(obj, key)\n    if obj == nil then return \"null\" end\n    if type(obj) == \"boolean\" or type(obj) == \"number\" then return tostring(obj) end\n    if type(obj) == \"string\" then return '\"' .. obj:gsub('\"', '\\\\\"') .. '\"' end\n    if type(obj) == \"table\" then\n        local isArray = true\n        local maxIndex = 0\n        for k, v in pairs(obj) do\n            if type(k) ~= \"number\" then isArray = false; break end\n            maxIndex = math.max(maxIndex, k)\n        end\n        \n        if isArray then\n            if maxIndex > 0 then\n                local items = {}\n                for i = 1, maxIndex do\n                    if obj[i] ~= nil then\n                        table.insert(items, json_encode_ordered(obj[i], key))\n                    else\n                        table.insert(items, \"null\")\n                    end\n                end\n                return \"[\" .. table.concat(items, \", \") .. \"]\"\n            else\n                return \"[]\"\n            end\n        else\n            -- Use field order maps for known object types (preorder traversal)\n            if key and FIELD_ORDERS[key] then\n                return encodeWithFieldOrder(obj, FIELD_ORDERS[key])\n            else\n                -- For unknown objects, use alphabetical ordering for consistency\n                local items = {}\n                local orderedKeys = {}\n                for k, v in pairs(obj) do\n                    if type(k) == \"number\" then\n                        table.insert(orderedKeys, {k, v, true})\n                    end\n                end\n                table.sort(orderedKeys, function(a, b) return a[1] < b[1] end)\n                \n                for k, v in pairs(obj) do\n                    if type(k) == \"string\" then\n                        table.insert(orderedKeys, {k, v, false})\n                    end\n                end\n                \n                for _, item in ipairs(orderedKeys) do\n                    local k, v, isNumeric = item[1], item[2], item[3]\n                    local keyStr = isNumeric and tostring(k) or '\"' .. k:gsub('\"', '\\\\\"') .. '\"'\n                    table.insert(items, keyStr .. ': ' .. json_encode_ordered(v, k))\n                end\n                return \"{\" .. table.concat(items, \", \") .. \"}\"\n            end\n        end\n    end\n    return '\"' .. tostring(obj) .. '\"'\nend\n\njson = { encode = json_encode }\n\nfunction findEventType(log)\n    if getNestedField(log, 'event_type') then\n        return 'authentication.' .. string.lower(getNestedField(log, 'event_type'))\n    elseif getNestedField(log, 'context') then\n        return 'telephony.' .. string.lower(getNestedField(log, 'context'))\n    elseif getNestedField(log, 'eventtype') then\n        local action = getNestedField(log, 'action') or 'unknown'\n        return 'administrator.' .. string.lower(action)\n    end\n    return 'unknown.unknown'\nend\n\nfunction buildObservablesFromMappings(event, mappings)\n    local observables = {}\n    \n    for _, mapping in ipairs(mappings) do\n        if mapping.type == \"observable\" then\n            local value = getNestedField(event, mapping.source)\n            if value and value ~= \"-\" then\n            table.insert(observables, {\n                    type_id = mapping.type_id,\n                    type = mapping.observable_type,\n                    name = mapping.name,\n                    value = value\n            })\n        end\n        end\n    end\n    \n    return observables\nend\n\nfunction iso8601_to_epoch_ms(timestr)\n    -- Try to parse with fractional seconds\n    local year, month, day, hour, min, sec, frac, offset_sign, offset_hour, offset_min =\n        timestr:match(\"^(%d+)%-(%d+)%-(%d+)T(%d+):(%d+):(%d+)%.(%d+)([+-])(%d+):(%d+)$\")\n\n    -- If fractional seconds not present, try without fraction\n    if not year then\n        year, month, day, hour, min, sec, offset_sign, offset_hour, offset_min =\n            timestr:match(\"^(%d+)%-(%d+)%-(%d+)T(%d+):(%d+):(%d+)([+-])(%d+):(%d+)$\")\n        frac = \"0\"\n    end\n\n    -- Handle Z (UTC) format\n    if not year then\n        year, month, day, hour, min, sec, frac = timestr:match(\"^(%d+)%-(%d+)%-(%d+)T(%d+):(%d+):(%d+)%.?(%d*)Z$\")\n        offset_sign, offset_hour, offset_min = \"+\", \"0\", \"0\"\n        if frac == \"\" then frac = \"0\" end\n    end\n\n    -- Convert to numeric\n    year, month, day, hour, min, sec = tonumber(year), tonumber(month), tonumber(day),\n                                       tonumber(hour), tonumber(min), tonumber(sec)\n    offset_hour, offset_min = tonumber(offset_hour), tonumber(offset_min)\n    local frac_ms = tonumber(frac:sub(1,3))  -- take first 3 digits as milliseconds\n\n    -- Convert to UTC timestamp\n    local utc_time = os.time({\n        year = year,\n        month = month,\n        day = day,\n        hour = hour,\n        min = min,\n        sec = sec\n    })\n\n    -- Adjust for timezone offset\n    local offset_seconds = offset_hour * 3600 + offset_min * 60\n    if offset_sign == \"+\" then\n        utc_time = utc_time - offset_seconds\n    else\n        utc_time = utc_time + offset_seconds\n    end\n\n    -- Return epoch milliseconds\n    return utc_time * 1000 + frac_ms\nend\n\n-- Apply mappings and add unmapped fields with \"unmapped.\" prefix\nfunction getParsedEvent(event, mappings)\n    local result = {}\n    local mappedFields = {}\n\n    -- Apply field mappings first\n    for _, mapping in ipairs(mappings) do\n        local value = nil\n\n        if mapping.type == \"computed\" then\n            value = mapping.value\n        elseif mapping.type == \"direct\" then\n            value = getNestedField(event, mapping.source)\n        elseif mapping.type == \"observable\" then\n            -- Observables handled elsewhere\n        end\n\n        if mapping.type == \"direct\" or mapping.type == \"computed\" then\n            -- Skip fields with value \"-\"\n            if value ~= \"-\" then\n                setNestedField(result, mapping.target, value)\n                mappedFields[mapping.target] = true\n                -- Also mark source field as mapped to prevent it from going to unmapped\n                if mapping.type == \"direct\" then\n                    mappedFields[mapping.source] = true\n                end\n            end\n        end\n    end\n    \n    -- Special handling for cloud.provider field (can't use getNestedField due to dot in field name)\n    if event['cloud.provider'] and event['cloud.provider'] ~= \"-\" then\n        result['cloud.provider'] = event['cloud.provider']\n        mappedFields['cloud.provider'] = true\n    end\n    \n    -- Special handling for dataSource object (set in processEvent, should not go to unmapped)\n    if event['dataSource'] and type(event['dataSource']) == 'table' then\n        result['dataSource'] = event['dataSource']\n        mappedFields['dataSource'] = true\n        -- Also mark individual dataSource fields as mapped\n        if event['dataSource'].category then\n            mappedFields['dataSource.category'] = true\n        end\n        if event['dataSource'].name then\n            mappedFields['dataSource.name'] = true\n        end\n        if event['dataSource'].vendor then\n            mappedFields['dataSource.vendor'] = true\n        end\n    end\n    \n    -- Special handling for event object (set in processEvent, should not go to unmapped)\n    if event['event'] and type(event['event']) == 'table' then\n        result['event'] = event['event']\n        mappedFields['event'] = true\n        -- Also mark individual event fields as mapped\n        if event['event'].type then\n            mappedFields['event.type'] = true\n        end\n    end\n    \n    -- Special handling for synthetic fields set in processEvent (should not go to unmapped)\n    local syntheticFields = {\n        'activity_id', 'activity_name', 'category_uid', 'category_name', \n        'class_uid', 'class_name', 'type_uid', 'type_name',\n        'OCSF_version', 'user'\n    }\n    for _, field in ipairs(syntheticFields) do\n        if event[field] then\n            -- If both result and event values are tables, merge without overwriting existing keys\n            if type(event[field]) == 'table' and type(result[field]) == 'table' then\n                for k, v in pairs(event[field]) do\n                    if result[field][k] == nil then\n                        result[field][k] = v\n                    end\n                end\n            else\n                result[field] = event[field]\n            end\n            mappedFields[field] = true\n        end\n    end\n\n    -- Copy remaining unmapped fields with prefix\n    for key, value in pairs(event) do\n        if not IGNORE_FIELDS[key] and not mappedFields[key] then\n            -- Skip fields with value \"-\"\n            if value ~= \"-\" then\n                if type(value) == 'table' then\n                    local nestedObj = {}\n                    for nestedKey, nestedValue in pairs(value) do\n                        if type(nestedValue) ~= 'function' and nestedValue ~= \"-\" then\n                            nestedObj[nestedKey] = nestedValue\n                        end\n                    end\n                    if next(nestedObj) then\n                        result[\"unmapped.\" .. key] = nestedObj\n                    end\n                else\n                    result[\"unmapped.\" .. key] = value\n                end\n            end\n        end\n    end\n\n    -- Convert time field to epoch milliseconds if it exists\n    if result.time then\n        result.time = iso8601_to_epoch_ms(result.time)\n    end\n\n    if FEATURES.FLATTEN_EVENT_TYPE then\n        if result and result.event then\n            result['event.type'] = result.event.type\n        end\n    end\n    return result\nend\n\nfunction processEvent(event)\n    if not event then return event end\n\n    -- Set eventtype based on _duo_event_type if eventtype doesn't exist\n    if getNestedField(event, '_duo_event_type') == 'administrator' and not getNestedField(event, 'eventtype') then\n        event.eventtype = 'administrator'\n    end\n\n    local eventType = findEventType(event)\n    local eventDef = eventTypeMappings[eventType] or eventTypeMappings[\"unknown.unknown\"]\n    \n    -- Step 1: Set site.id (setSiteId equivalent)\n    -- Load site ID from event data (site.id, site_id, or siteId)\n    local siteId = getNestedField(event, 'site.id') or getNestedField(event, 'site_id') or getNestedField(event, 'siteId')\n    if siteId then\n        if not event.site then event.site = {} end\n        event.site.id = siteId\n    end\n    \n\n\n    local msg_event = {}\n    for k, v in pairs(event) do\n        if (not IGNORE_FIELDS[k]) then\n            msg_event[k] = v\n        end\n    end\n    event[\"message\"] = json_encode_ordered(msg_event, 'message_all')\n    \n    -- Step 3: Apply synthetic fields (setciscoDuoSyntheticFields equivalent)\n    if eventDef.activity_id then event.activity_id = eventDef.activity_id end\n    if eventDef.activity_name then event.activity_name = eventDef.activity_name end\n    if eventDef.category_uid then event.category_uid = eventDef.category_uid end\n    if eventDef.category_name then event.category_name = eventDef.category_name end\n    if eventDef.class_uid then event.class_uid = eventDef.class_uid end\n    if eventDef.class_name then event.class_name = eventDef.class_name end\n    if eventDef.type_uid then event.type_uid = eventDef.type_uid end\n    if eventDef.type_name then event.type_name = eventDef.type_name end\n    \n    -- Set event object\n    event['event'] = {type = eventDef.event_type}\n    \n    -- Add user object for administrator events\n    if string.find(eventType, '^administrator') and eventDef.user_type_id then\n        event['user'] = {type_id = eventDef.user_type_id}\n    end\n    \n    -- Add status_id for admin_create events\n    if eventDef.status_id then\n        event['status_id'] = eventDef.status_id\n    end\n    \n    if eventDef.is_mfa then\n        event['is_mfa'] = eventDef.is_mfa\n    end\n    \n    if eventDef.cloud_provider then\n        event['cloud.provider'] = eventDef.cloud_provider\n    end\n    \n    -- Set observables (from setciscoDuoSyntheticFields)\n    local observables = buildObservablesFromMappings(event, eventDef.mappings)\n    if #observables > 0 then \n        event.observables = observables\n    end\n    \n    -- Set common fields (from setciscoDuoSyntheticFields end)\n    event[\"dataSource\"] = {name = \"Cisco Duo\", category = \"security\", vendor = \"Cisco\"}\n    event[\"OCSF_version\"] = \"1.0.0\"\n    -- Step 4: Apply field mappings and unmapped handling (getParsedEvent parity)\n    return getParsedEvent(event, eventDef.mappings)\nend\n\nfunction process(event, emit)\n    local out = processEvent(event[\"log\"])\n    if out ~= nil then\n        event[\"log\"] = out\n        emit(event)\n    end\nend\n\n",
                        "serializer": "cisco-duo-lua"
                    }
                ]
            },
            "status": "NS_ACTIVE",
            "created": "2025-11-19T22:17:26.436485Z",
            "updated": "2025-11-19T22:17:26.436485Z",
            "createdBy": "",
            "updatedBy": "",
            "isTransformGroup": false,
            "origin": "NODE_ORIGIN_USER",
            "templateName": "OCSFSerializer",
            "processorType": "DATA_PROCESSOR",
            "siteFilenames": [],
            "userVisible": true
        }
    ],
    "archivalDestination": null
}
